{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meryltheng/DeepLearningA-Z/blob/main/Boltzmann_Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#Boltzmann Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbiqOK7dLGG"
      },
      "source": [
        "##Downloading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset info: https://grouplens.org/datasets/movielens/"
      ],
      "metadata": {
        "id": "pU1FY8rVwIi7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL5MEkLcfRD2"
      },
      "source": [
        "###ML-100K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjOPzue7FCXJ",
        "outputId": "d2d075d3-65a0-4881-e5fe-b6d02f59e416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "!unzip ml-100k.zip\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-15 07:45:25--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  27.3MB/s    in 0.2s    \n",
            "\n",
            "2023-06-15 07:45:25 (27.3 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n",
            "ml-100k  ml-100k.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xis6ldDfTs6"
      },
      "source": [
        "###ML-1M"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOly1yfAfTjd",
        "outputId": "891b469b-9a30-474d-ffba-d985c4284a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "!unzip ml-1m.zip\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-15 07:45:26--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "\rml-1m.zip             0%[                    ]       0  --.-KB/s               \rml-1m.zip           100%[===================>]   5.64M  31.3MB/s    in 0.2s    \n",
            "\n",
            "2023-06-15 07:45:26 (31.3 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n",
            "ml-100k  ml-100k.zip  ml-1m  ml-1m.zip\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOBJ8UCXdY0g"
      },
      "source": [
        "##Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LvGeU1CeCtg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM04FyMudkoK"
      },
      "source": [
        "## Importing the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJw2p3-Cewo4"
      },
      "source": [
        "# We won't be using this dataset.\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See data file descriptions in `README` file."
      ],
      "metadata": {
        "id": "lSoUwkIp0Ab7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTIbE2tkdkwP"
      },
      "source": [
        "## Preparing the training set and the test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to `README` file in `ml-100k` folder."
      ],
      "metadata": {
        "id": "wx7kKT9P00J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
        "training_set = np.array(training_set, dtype = 'int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "metadata": {
        "id": "j5iKcHoOwdW1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCf8HjSydk4s"
      },
      "source": [
        "## Getting the number of users and movies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make one matrix for training and one for test set. These matrices will have the same number of users and movies (i.e., rows and cols).\n",
        "\n",
        "Maximum user/movie ID needs to correspond to ALL data splits, especially when doing k-fold cross-validation."
      ],
      "metadata": {
        "id": "yt81JHOC3d_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "metadata": {
        "id": "cI6e0Sj025tO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-w4-hVidlAm"
      },
      "source": [
        "## Converting the data into an array with users in lines and movies in columns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):  # add 1 bc python is annoying with indexing\n",
        "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
        "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings # minus 1 for indexes to correspond\n",
        "    new_data.append(list(ratings)) # list of lists - what Torch expects\n",
        "  return new_data\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "rATLlJyl5imu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMmhuUpldlHo"
      },
      "source": [
        "## Converting the data into Torch tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = torch.FloatTensor(training_set) # expects a list of lists\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "pcGhrKMj-kEB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIPruubGdlPW"
      },
      "source": [
        "## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[training_set == 0] = -1 # movies not rated\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "metadata": {
        "id": "4xKYWoL1AFvV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kkL8NkkdlZj"
      },
      "source": [
        "## Creating the architecture of the Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to build a probabilistic graphical model through a class. Classes are the most practical way to build/create anything in python. It's an ensemble of instructions and a model for what we want to build.\n",
        "\n",
        "Three functions in this class:\n",
        "\n",
        "\n",
        "1.   Initialise the RBM\n",
        "2.   Sample the probabilities of the hidden nodes `h` given the visible nodes `v`\n",
        "3.   Sample the probabilities of the visible nodes `v` given the hidden nodes `h`\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVQlIn6-DFO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RBM():\n",
        "  def __init__(self, nv, nh):# init function is compulsory in any class; default function\n",
        "     self.W = torch.randn(nh, nv) # initialises a tensor of size nh, nv acc to a normal distribution with mean 0 and sd 1\n",
        "     self.a = torch.randn(1, nh) # one bias for each hidden node; 2D-tensor n_batch X n_bias\n",
        "     self.b = torch.randn(1, nv)\n",
        "  def sample_h(self, x): # x corresponds to v\n",
        "    wx = torch.mm(x, self.W.t()) # product of two tensors; note we take the transposed W for matrix dims to agree\n",
        "    activation = wx + self.a.expand_as(wx) # weights + bias ; `.expand_as` function to apply bias to each line of the mini-batch\n",
        "    p_h_given_v = torch.sigmoid(activation) # probability the hidden node is activated given the visible node\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v) # 2nd arg returns sample of hidden neurons based on probabilities\n",
        "  def sample_v(self, y):\n",
        "    wy = torch.mm(y, self.W) # note that we do not transpose W here bc matrix dims already agree\n",
        "    activation = wy + self.b.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "  def train(self, v0, vk, ph0, phk): # Contrastive Divergence based on algo 1 in Fischer & Igel (2012)\n",
        "    self.W += (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t() # update weights\n",
        "    self.b += torch.sum((v0 - vk), 0) # 2nd arg to keep tensor to 2D\n",
        "    self.a += torch.sum((ph0 - phk), 0)"
      ],
      "metadata": {
        "id": "IL7UweQcAGS4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note on RBM:**\n",
        "The standard type of RBM has binary-valued (Boolean) hidden and visible units, and consists of a matrix of weights $W$ of size $m \\times n$. Each weight element $w_{i,j}$ of the matrix is associated with the connection between the visible (input) unit $v_i$ and the hidden unit $h_j$. In addition, there are bias weights (offsets) $a_i$ for $v_i$ and $b_i$ for $h_j$. Given the weights and biases, the energy of a configuration (pair of boolean vectors) ($v,h$) is defined as\n",
        "\n",
        "$$ E(v,h) = - \\sum_i{a_i v_i} - \\sum_j{b_j h_j} - \\sum_i \\sum_j{v_i w_{i,j} h_j}$$ .\n",
        "\n",
        "The joint probability distribution for the visible and hidden vectors is defined in terms of the energy function as follows,\n",
        "\n",
        "$$ P(v,h) = - \\frac{1}{Z} e^{-E(v,h)}$$\n",
        "\n",
        "where $Z$ is a partition function defined as the sum of $e^{-E(v,h)}$ over all possible configurations, which can be interpreted as a normalizing constant to ensure that the probabilities sum to 1.\n",
        "\n",
        "More here: https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine\n",
        "\n",
        "[Note: biases are analogous to the role of a constant in a linear function]"
      ],
      "metadata": {
        "id": "bvqcxIHBIzES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create RMB object"
      ],
      "metadata": {
        "id": "O2Nc6FN4hckA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nv = len(training_set[0]) # no. of movies\n",
        "nh = 100 # param we can choose and tune; no. features we detect\n",
        "batch_size = 100 # tunable param; big batch size, faster training\n",
        "rbm = RBM(nv, nh) # creates RMB object"
      ],
      "metadata": {
        "id": "j6OOfKC6gLlg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gy59alAdloL"
      },
      "source": [
        "## Training the RBM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0 # initialised value\n",
        "  s = 0. # counter that is a float\n",
        "  for id_user in range(0, nb_users - batch_size, batch_size): # 3rd arg is the step size\n",
        "    vk = training_set[id_user : id_user + batch_size] # input batch to be updated\n",
        "    v0 = training_set[id_user : id_user + batch_size] # won't be updated; original ratings of users (ie. target)\n",
        "    ph0,_ = rbm.sample_h(v0) # `,_` returns first element of function\n",
        "    for k in range(10): # k-step contrastive divergence\n",
        "      _,hk = rbm.sample_h(vk)\n",
        "      _,vk = rbm.sample_v(hk)\n",
        "      vk[v0<0] = v0[v0<0] # ensure training does not happen on movies that weren't rated (== -1)\n",
        "    phk,_ = rbm.sample_h(vk)\n",
        "    rbm.train(v0, vk, ph0, phk) # this executes training, does not return anything\n",
        "    train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
        "    s += 1. # counter to normalise the train loss\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrKbZjK3AGu-",
        "outputId": "b0b3bc9f-379c-4f64-965e-4917f96674f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.3569)\n",
            "epoch: 2 loss: tensor(0.2452)\n",
            "epoch: 3 loss: tensor(0.2522)\n",
            "epoch: 4 loss: tensor(0.2524)\n",
            "epoch: 5 loss: tensor(0.2471)\n",
            "epoch: 6 loss: tensor(0.2497)\n",
            "epoch: 7 loss: tensor(0.2464)\n",
            "epoch: 8 loss: tensor(0.2498)\n",
            "epoch: 9 loss: tensor(0.2445)\n",
            "epoch: 10 loss: tensor(0.2488)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that we get one wrong prediction every four times in the training set (loss = 0.25)."
      ],
      "metadata": {
        "id": "89EXhxQUUdIw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bak5uc8gd-gX"
      },
      "source": [
        "## Testing the RBM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"blind-walk\" technique (from MCMC; close to random-walk but probabilities are not the same) is anagolous to having to stay on a straight line while blindfolded. Model has been trained to do this for 10 steps, so there is a high chance of 'staying on the line' when making single steps -- it is much easier!"
      ],
      "metadata": {
        "id": "71u9PqbCYKbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users): # batch_size is a technique specific to the training; don't need it here\n",
        "  v = training_set[id_user : id_user + 1] # training set is the input used to activate the hidden neurons to predict the output\n",
        "  vt = test_set[id_user : id_user + 1]\n",
        "  if len(vt[vt >= 0]) > 0: # the blind-walk is one step, so loop is removed; instead, we have a filter for only existing ratings (>0)\n",
        "    _,h = rbm.sample_h(v)\n",
        "    _,v = rbm.sample_v(h)\n",
        "    test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
        "    s += 1.\n",
        "print('test loss ' +str(test_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRZhpzP9VKGk",
        "outputId": "7fb1e609-3e76-43b3-f763-339d203f1f6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss tensor(0.2432)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model predicted test set slightly better than training set (loss < 0.25)!"
      ],
      "metadata": {
        "id": "uSy1vIerCR3R"
      }
    }
  ]
}